llm:
  provider: "openai"
  model: "gpt-4-turbo-preview"
  temperature: 0.1
  max_tokens: 16000
  
extraction:
  # Shatalov constraints
  max_blocks_per_card: 7
  min_blocks_per_card: 5
  max_anchors_per_block: 3
  min_anchors_per_block: 1
  
  # Extraction priorities
  prioritize_prerequisites: true
  prioritize_contrasts: true
  extract_examples: true
  extract_mistakes: true
  
validation:
  require_contrasts: true
  min_prerequisites_for_methods: 1
  warn_on_knowledge_islands: true
  min_concepts: 3
  
output:
  json: true
  markdown: true
  verbose: true
